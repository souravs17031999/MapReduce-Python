{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0b5"
    },
    "colab": {
      "name": "mapreduce (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFnnqdaEtk5E",
        "colab_type": "text"
      },
      "source": [
        "# Python Hadoop MapReduce: Analyzing AWS S3 Bucket Logs with mrjob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFBaWRtftk5I",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH0kyAeMtk5J",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "From PyPI:\n",
        "\n",
        "``pip install mrjob``\n",
        "\n",
        "From source:\n",
        "\n",
        "``python setup.py install``\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDSefzbItk5K",
        "colab_type": "text"
      },
      "source": [
        "## Processing S3 Logs\n",
        "\n",
        "Sample mrjob code that processes log files on Amazon S3 based on the [S3 logging format](http://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1SN-VGFtk5L",
        "colab_type": "code",
        "colab": {},
        "outputId": "df8141ae-7c4c-423d-be1f-bf9026e8c8d6"
      },
      "source": [
        "pip install mrjob"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mrjob\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/71/4821a7fa49d1e7be2d0defbdc394982b28994d97834ef5400c85bb91b66d/mrjob-0.6.12-py2.py3-none-any.whl (435kB)\n",
            "Collecting boto3>=1.4.6\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/a9/1ceaeda8aa5d3effc9098ae301820e27bf54c4000ec6f8ec79f9b265c50e/boto3-1.10.19-py2.py3-none-any.whl (128kB)\n",
            "Collecting botocore>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/18/e5/0f29669244ffacc15c4cec9e10d75c26e7d300e1786e79514e62373e648c/botocore-1.13.19-py2.py3-none-any.whl (5.4MB)\n",
            "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyyaml-5.1.1-py3.7-win-amd64.egg (from mrjob) (5.1.1)\n",
            "Collecting google-cloud-logging>=1.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/06/3a89173f80d02d275ab4fdca5283a7fdb84845e214f3383b5d52c29f4b5f/google_cloud_logging-1.14.0-py2.py3-none-any.whl (134kB)\n",
            "Collecting google-cloud-dataproc>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/2c/d702eb5be11f3a492b426b9756e3fdbe50869933261a6f98d970dd070c8e/google_cloud_dataproc-0.6.1-py2.py3-none-any.whl (264kB)\n",
            "Collecting google-cloud-storage>=1.13.1\n",
            "  Downloading https://files.pythonhosted.org/packages/87/78/7cf94b3d0961b1a3036ba351c7fdc04170baa73d20fcb41240da214c83fd/google_cloud_storage-1.23.0-py2.py3-none-any.whl (72kB)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.3.0,>=0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore>=1.6.0->mrjob) (1.23)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore>=1.6.0->mrjob) (0.14)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore>=1.6.0->mrjob) (2.7.5)\n",
            "Collecting google-cloud-core<2.0dev,>=1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/f0/084f598629db8e6ec3627688723875cdb03637acb6d86999bb105a71df64/google_cloud_core-1.0.3-py2.py3-none-any.whl\n",
            "Collecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/29/3a/c528ef37f48d6ffba16f0f3c0426456ba21e0dd32be9c61a2ade93e07faa/google_api_core-1.14.3-py2.py3-none-any.whl (68kB)\n",
            "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
            "Collecting google-auth>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore>=1.6.0->mrjob) (1.11.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (41.0.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (2.19.1)\n",
            "Requirement already satisfied: pytz in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (2018.5)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\protobuf-3.8.0-py3.7.egg (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (3.8.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\grpcio-1.21.1-py3.7-win-amd64.egg (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (1.21.1)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
            "Collecting cachetools<3.2,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
            "Collecting rsa<4.1,>=3.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (2018.4.16)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (2.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-logging>=1.9.0->mrjob) (3.0.4)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
            "Building wheels for collected packages: googleapis-common-protos\n",
            "  Building wheel for googleapis-common-protos (setup.py): started\n",
            "  Building wheel for googleapis-common-protos (setup.py): finished with status 'done'\n",
            "  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.6.0-cp37-none-any.whl size=77586 sha256=2663290d6e5089d09e373b4ae3300a744e4b69e106252ecc07142155dd27ffbe\n",
            "  Stored in directory: C:\\Users\\DELL\\AppData\\Local\\pip\\Cache\\wheels\\9e\\3d\\a2\\1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\n",
            "Successfully built googleapis-common-protos\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, googleapis-common-protos, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, google-api-core, google-cloud-core, google-cloud-logging, google-cloud-dataproc, google-resumable-media, google-cloud-storage, mrjob\n",
            "Successfully installed boto3-1.10.19 botocore-1.13.19 cachetools-3.1.1 google-api-core-1.14.3 google-auth-1.7.1 google-cloud-core-1.0.3 google-cloud-dataproc-0.6.1 google-cloud-logging-1.14.0 google-cloud-storage-1.23.0 google-resumable-media-0.5.0 googleapis-common-protos-1.6.0 jmespath-0.9.4 mrjob-0.6.12 pyasn1-0.4.8 pyasn1-modules-0.2.7 rsa-4.0 s3transfer-0.2.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-w4MNc3tk5Q",
        "colab_type": "code",
        "colab": {},
        "outputId": "dfe7585a-2dc3-427a-8220-8eb17b0fa10e"
      },
      "source": [
        "%%file mr_s3_log_parser.py\n",
        "\n",
        "import time\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.protocol import RawValueProtocol, ReprProtocol\n",
        "import re\n",
        "\n",
        "\n",
        "class MrS3LogParser(MRJob):\n",
        "    \"\"\"Parses the logs from S3 based on the S3 logging format:\n",
        "    http://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html\n",
        "    \n",
        "    Aggregates a user's daily requests by user agent and operation\n",
        "    \n",
        "    Outputs date_time, requester, user_agent, operation, count\n",
        "    \"\"\"\n",
        "\n",
        "    LOGPATS  = r'(\\S+) (\\S+) \\[(.*?)\\] (\\S+) (\\S+) ' \\\n",
        "               r'(\\S+) (\\S+) (\\S+) (\"([^\"]+)\"|-) ' \\\n",
        "               r'(\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) ' \\\n",
        "               r'(\"([^\"]+)\"|-) (\"([^\"]+)\"|-)'\n",
        "    NUM_ENTRIES_PER_LINE = 17\n",
        "    logpat = re.compile(LOGPATS)\n",
        "\n",
        "    (S3_LOG_BUCKET_OWNER, \n",
        "     S3_LOG_BUCKET, \n",
        "     S3_LOG_DATE_TIME,\n",
        "     S3_LOG_IP, \n",
        "     S3_LOG_REQUESTER_ID, \n",
        "     S3_LOG_REQUEST_ID,\n",
        "     S3_LOG_OPERATION, \n",
        "     S3_LOG_KEY, \n",
        "     S3_LOG_HTTP_METHOD,\n",
        "     S3_LOG_HTTP_STATUS, \n",
        "     S3_LOG_S3_ERROR, \n",
        "     S3_LOG_BYTES_SENT,\n",
        "     S3_LOG_OBJECT_SIZE, \n",
        "     S3_LOG_TOTAL_TIME, \n",
        "     S3_LOG_TURN_AROUND_TIME,\n",
        "     S3_LOG_REFERER, \n",
        "     S3_LOG_USER_AGENT) = range(NUM_ENTRIES_PER_LINE)\n",
        "\n",
        "    DELIMITER = '\\t'\n",
        "\n",
        "    # We use RawValueProtocol for input to be format agnostic\n",
        "    # and avoid any type of parsing errors\n",
        "    INPUT_PROTOCOL = RawValueProtocol\n",
        "\n",
        "    # We use RawValueProtocol for output so we can output raw lines\n",
        "    # instead of (k, v) pairs\n",
        "    OUTPUT_PROTOCOL = RawValueProtocol\n",
        "\n",
        "    # Encode the intermediate records using repr() instead of JSON, so the\n",
        "    # record doesn't get Unicode-encoded\n",
        "    INTERNAL_PROTOCOL = ReprProtocol\n",
        "\n",
        "    def clean_date_time_zone(self, raw_date_time_zone):\n",
        "        \"\"\"Converts entry 22/Jul/2013:21:04:17 +0000 to the format\n",
        "        'YYYY-MM-DD HH:MM:SS' which is more suitable for loading into\n",
        "        a database such as Redshift or RDS\n",
        "\n",
        "        Note: requires the chars \"[ ]\" to be stripped prior to input\n",
        "        Returns the converted datetime annd timezone\n",
        "        or None for both values if failed\n",
        "\n",
        "        TODO: Needs to combine timezone with date as one field\n",
        "        \"\"\"\n",
        "        date_time = None\n",
        "        time_zone_parsed = None\n",
        "\n",
        "        # TODO: Probably cleaner to parse this with a regex\n",
        "        date_parsed = raw_date_time_zone[:raw_date_time_zone.find(\":\")]\n",
        "        time_parsed = raw_date_time_zone[raw_date_time_zone.find(\":\") + 1:\n",
        "                                         raw_date_time_zone.find(\"+\") - 1]\n",
        "        time_zone_parsed = raw_date_time_zone[raw_date_time_zone.find(\"+\"):]\n",
        "\n",
        "        try:\n",
        "            date_struct = time.strptime(date_parsed, \"%d/%b/%Y\")\n",
        "            converted_date = time.strftime(\"%Y-%m-%d\", date_struct)\n",
        "            date_time = converted_date + \" \" + time_parsed\n",
        "\n",
        "        # Throws a ValueError exception if the operation fails that is\n",
        "        # caught by the calling function and is handled appropriately\n",
        "        except ValueError as error:\n",
        "            raise ValueError(error)\n",
        "        else:\n",
        "            return converted_date, date_time, time_zone_parsed\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        line = line.strip()\n",
        "        match = self.logpat.search(line)\n",
        "\n",
        "        date_time = None\n",
        "        requester = None\n",
        "        user_agent = None\n",
        "        operation = None\n",
        "\n",
        "        try:\n",
        "            for n in range(self.NUM_ENTRIES_PER_LINE):\n",
        "                group = match.group(1 + n)\n",
        "\n",
        "                if n == self.S3_LOG_DATE_TIME:\n",
        "                    date, date_time, time_zone_parsed = \\\n",
        "                        self.clean_date_time_zone(group)\n",
        "                    # Leave the following line of code if \n",
        "                    # you want to aggregate by date\n",
        "                    date_time = date + \" 00:00:00\"\n",
        "                elif n == self.S3_LOG_REQUESTER_ID:\n",
        "                    requester = group\n",
        "                elif n == self.S3_LOG_USER_AGENT:\n",
        "                    user_agent = group\n",
        "                elif n == self.S3_LOG_OPERATION:\n",
        "                    operation = group\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "        except Exception:\n",
        "            yield ((\"Error while parsing line: %s\", line), 1)\n",
        "        else:\n",
        "            yield ((date_time, requester, user_agent, operation), 1)\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        output = list(key)\n",
        "        output = self.DELIMITER.join(output) + \\\n",
        "                 self.DELIMITER + \\\n",
        "                 str(sum(values))\n",
        "\n",
        "        yield None, output\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            self.mr(mapper=self.mapper,\n",
        "                    reducer=self.reducer)\n",
        "        ]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MrS3LogParser.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting mr_s3_log_parser.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-d3TDoStk5T",
        "colab_type": "text"
      },
      "source": [
        "## Running Amazon Elastic MapReduce Jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdI5Cl4ttk5T",
        "colab_type": "text"
      },
      "source": [
        "Run an Amazon Elastic MapReduce (EMR) job on the given input (must be a flat file hierarchy), placing the results in the output (output directory must not exist):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dda3suMbtk5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python mr_s3_log_parser.py -r emr s3://bucket-source/ --output-dir=s3://bucket-dest/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBggz1Rjtk5X",
        "colab_type": "text"
      },
      "source": [
        "Run a MapReduce job locally on the specified input file, sending the results to the specified output file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAD2jAaytk5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python mr_s3_log_parser.py input_data.txt > output_data.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgZh1Vqitk5b",
        "colab_type": "text"
      },
      "source": [
        "## Sample Config File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-EXYNgFtk5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runners:\n",
        "  emr:\n",
        "    aws_access_key_id: __ACCESS_KEY__\n",
        "    aws_secret_access_key: __SECRET_ACCESS_KEY__\n",
        "    aws_region: us-east-1\n",
        "    ec2_key_pair: EMR\n",
        "    ec2_key_pair_file: ~/.ssh/EMR.pem\n",
        "    ssh_tunnel_to_job_tracker: true\n",
        "    ec2_master_instance_type: m3.xlarge\n",
        "    ec2_instance_type: m3.xlarge\n",
        "    num_ec2_instances: 5\n",
        "    s3_scratch_uri: s3://bucket/tmp/\n",
        "    s3_log_uri: s3://bucket/tmp/logs/\n",
        "    enable_emr_debugging: True\n",
        "    bootstrap:\n",
        "    - sudo apt-get install -y python-pip\n",
        "    - sudo pip install --upgrade simplejson"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}